{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Winning Jeopardy\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. \n",
    "\n",
    "For the purpose of this project, let's say we want to compete on Jeopardy, and we're looking for any edge we can get to win. \n",
    "\n",
    "We'll work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help us win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "jeopardy = pd.read_csv(\"jeopardy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the dataset above, each row represents a single question on a single episode of Jeopardy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some column names have spaces in front. We are going to fix them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy.columns = jeopardy.columns.str.replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 7 columns):\n",
      "ShowNumber    19999 non-null int64\n",
      "AirDate       19999 non-null object\n",
      "Round         19999 non-null object\n",
      "Category      19999 non-null object\n",
      "Value         19999 non-null object\n",
      "Question      19999 non-null object\n",
      "Answer        19999 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing Text\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing any analysis, we need to normalize all text columns (Question and Answer columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize(string):\n",
    "    string = string.lower()\n",
    "    string = re.sub(\"[^A-Za-z0-9\\s]\", \"\", string)\n",
    "    string = re.sub(\"\\s+\", \" \", string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we wrote a function to take in a string, convert it to lowercase, and remove all punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy[\"clean_question\"] = jeopardy[\"Question\"].apply(normalize)\n",
    "jeopardy[\"clean_answer\"] = jeopardy[\"Answer\"].apply(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing Columns\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to convert the Value column from text to numeric, and also the AirDate column should be a datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to normalize dollar values\n",
    "\n",
    "def normalize_value(value):\n",
    "    value = re.sub(\"[^A-Za-z0-9\\s]\", \"\", value)\n",
    "    try:\n",
    "        value = int(value)\n",
    "    except Exception:\n",
    "        value=0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jeopardy[\"clean_value\"] = jeopardy[\"Value\"].apply(normalize_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy[\"AirDate\"] = pd.to_datetime(jeopardy[\"AirDate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShowNumber                 int64\n",
       "AirDate           datetime64[ns]\n",
       "Round                     object\n",
       "Category                  object\n",
       "Value                     object\n",
       "Question                  object\n",
       "Answer                    object\n",
       "clean_question            object\n",
       "clean_answer              object\n",
       "clean_value                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers in Questions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's figure out these two things:\n",
    "\n",
    "* How often the answer is deducible from the question.\n",
    "* How often new questions are repeats of older questions.\n",
    "\n",
    "We can answer the first question by seeing how many times words in the answer also occur in the question.\n",
    "\n",
    "We can answer the second question by seeing how often complex words (> 6 characters) reoccur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to count word matches between questions and answers\n",
    "\n",
    "def count_matches(row):\n",
    "    split_answer = row[\"clean_answer\"].split()\n",
    "    split_question = row[\"clean_question\"].split()\n",
    "    match_count = 0\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\")\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    for i in split_answer:\n",
    "        if i in split_question:\n",
    "            match_count +=1\n",
    "    return match_count/len(split_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(count_matches, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05900196524977763"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"answer_in_question\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000    87.379\n",
       "0.111111     0.010\n",
       "0.125000     0.045\n",
       "0.142857     0.105\n",
       "0.166667     0.135\n",
       "0.181818     0.010\n",
       "0.200000     0.340\n",
       "0.250000     0.775\n",
       "0.285714     0.035\n",
       "0.300000     0.010\n",
       "0.333333     2.470\n",
       "0.350000     0.005\n",
       "0.400000     0.130\n",
       "0.428571     0.010\n",
       "0.444444     0.005\n",
       "0.500000     7.240\n",
       "0.571429     0.010\n",
       "0.600000     0.045\n",
       "0.666667     0.520\n",
       "0.750000     0.085\n",
       "0.800000     0.010\n",
       "0.875000     0.005\n",
       "1.000000     0.620\n",
       "Name: answer_in_question, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(jeopardy[\"answer_in_question\"].value_counts(normalize=True).sort_index()*100).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it won't be easy to find the answer from the question as it has a very low mean value 6%. A big proportion of the answers does not include any word from the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recycled Questions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to investigate how often new questions are repeats of older ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "jeopardy = jeopardy.sort_values(by=\"AirDate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in jeopardy.iterrows():\n",
    "    split_question = row[\"clean_question\"].split(\" \")\n",
    "    split_question = [q for q in split_question if len(q) > 5]\n",
    "    match_count = 0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count +=1\n",
    "    for word in split_question:\n",
    "        terms_used.add(word)\n",
    "    if len(split_question) > 0:\n",
    "        match_count /= len(split_question)\n",
    "    question_overlap.append(match_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jeopardy[\"question_overlap\"] = question_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6876260592169802"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"question_overlap\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found that about 70% overlap between words in new question and words in old questions. Although 70% is a big proportion, we only looked at a small set of questions, and our code doesn't look at phrases, it looks only at single words. This makes it relatively insignificant. We should do more investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low Value vs High Value Questions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we only want to study questions that have higher values instead of low value questions. This may help us earn more money when we're on Jeopardy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually do that by figuring out which terms correspond to high-value questions using a chi-squared test. We'll first need to narrow down the questions into two categories:\n",
    "\n",
    "* Low value -- Any row where Value is less than 800.\n",
    "* High value -- Any row where Value is greater than 800."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to determine high and low value questions\n",
    "\n",
    "def determine_value(row):\n",
    "    if row[\"clean_value\"] > 800:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy[\"high_value\"] = jeopardy.apply(determine_value, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to determine low and high word usage\n",
    "\n",
    "def usage_count(word):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for index, row in jeopardy.iterrows():\n",
    "        split_question = row[\"clean_question\"].split(\" \")\n",
    "        if word in split_question:\n",
    "            if row[\"high_value\"] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "terms_used_list = list(terms_used)\n",
    "comparison_terms = [choice(terms_used_list) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instructed',\n",
       " 'polonius',\n",
       " 'corbin',\n",
       " 'blondes',\n",
       " 'subsidies',\n",
       " 'minerva',\n",
       " 'pompeys',\n",
       " 'afikomen',\n",
       " 'leningrad',\n",
       " 'contempt']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_terms[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly chose 10 words for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observed_expected = []\n",
    "\n",
    "for i in comparison_terms:\n",
    "    observed_expected.append(usage_count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 3),\n",
       " (0, 2),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 1)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the Chi-Squared Test\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the expected counts and the chi-squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "high_value_count = (jeopardy[\"high_value\"] == 1).sum()\n",
    "low_value_count = (jeopardy[\"high_value\"] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "chi_squared=[]\n",
    "\n",
    "for i in observed_expected:\n",
    "    total = sum(i)\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    expected_high = total_prop*high_value_count\n",
    "    expected_low = total_prop*low_value_count\n",
    "    observed = np.array([i[0], i[1]])\n",
    "    expected = np.array([expected_high, expected_low])\n",
    "    chi_squared.append(chisquare(observed, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=1.205888538380652, pvalue=0.27214791766902047),\n",
       " Power_divergenceResult(statistic=0.803925692253768, pvalue=0.3699222378079571),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like none of the words is significantly different in usage between high value and low value questions. The p_values are higher than 0.05, so the chi-squared test isn't as valid. \n",
    "\n",
    "It might be better to run this test with only terms that have higher frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Used Words\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "term_list = []\n",
    "\n",
    "for index, row in jeopardy.iterrows():\n",
    "    split_question = row[\"clean_question\"].split(\" \")\n",
    "    split_question = [q for q in split_question if len(q) > 5]\n",
    "    for word in split_question:\n",
    "        term_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "term_sr = pd.Series(term_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "called              521\n",
       "country             476\n",
       "played              297\n",
       "became              287\n",
       "before              267\n",
       "president           258\n",
       "capital             257\n",
       "american            257\n",
       "famous              246\n",
       "targetblankherea    244\n",
       "french              243\n",
       "island              216\n",
       "people              184\n",
       "national            183\n",
       "largest             179\n",
       "little              178\n",
       "around              169\n",
       "british             166\n",
       "author              164\n",
       "meaning             162\n",
       "during              161\n",
       "century             159\n",
       "family              155\n",
       "musical             153\n",
       "company             151\n",
       "series              148\n",
       "between             145\n",
       "states              142\n",
       "reports             141\n",
       "founded             141\n",
       "character           141\n",
       "targetblankthisa    140\n",
       "include             138\n",
       "million             129\n",
       "number              125\n",
       "school              120\n",
       "popular             119\n",
       "father              114\n",
       "because             111\n",
       "through             104\n",
       "classic             103\n",
       "german               99\n",
       "italian              99\n",
       "george               98\n",
       "former               98\n",
       "leader               97\n",
       "another              97\n",
       "america              97\n",
       "william              96\n",
       "english              95\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_sr.value_counts().head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the top 50 most used words in the questions of Jeopardy. Based on this output above, we can study topics around these words. It may increase the chance of a win. However, we should also calculate expected counts and the chi-squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comp_terms_50 = list(term_sr.value_counts().head(50).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obs_exp_50 = []\n",
    "\n",
    "for i in comp_terms_50:\n",
    "    obs_exp_50.append(usage_count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chi_squared_50 = []\n",
    "\n",
    "for i in obs_exp_50:\n",
    "    total = sum(i)\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    exp_high = total_prop*high_value_count\n",
    "    exp_low = total_prop*low_value_count\n",
    "    observed = np.array([i[0], i[1]])\n",
    "    expected = np.array([exp_high, exp_low])\n",
    "    for w in comp_terms_50:\n",
    "        chi_squared_50.append([w,chisquare(observed, expected)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['called',\n",
       "  Power_divergenceResult(statistic=4.048305063534577, pvalue=0.044215717944225866)],\n",
       " ['country',\n",
       "  Power_divergenceResult(statistic=4.048305063534577, pvalue=0.044215717944225866)],\n",
       " ['played',\n",
       "  Power_divergenceResult(statistic=4.048305063534577, pvalue=0.044215717944225866)],\n",
       " ['became',\n",
       "  Power_divergenceResult(statistic=4.048305063534577, pvalue=0.044215717944225866)],\n",
       " ['before',\n",
       "  Power_divergenceResult(statistic=4.048305063534577, pvalue=0.044215717944225866)]]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared_50[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put our result into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chi_50_df = pd.DataFrame(chi_squared_50, columns=[\"word\",\"chi-square-result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>chi-square-result</th>\n",
       "      <th>chi-square</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>called</td>\n",
       "      <td>(4.048305063534577, 0.044215717944225866)</td>\n",
       "      <td>4.048305</td>\n",
       "      <td>0.044216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>country</td>\n",
       "      <td>(4.048305063534577, 0.044215717944225866)</td>\n",
       "      <td>4.048305</td>\n",
       "      <td>0.044216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>played</td>\n",
       "      <td>(4.048305063534577, 0.044215717944225866)</td>\n",
       "      <td>4.048305</td>\n",
       "      <td>0.044216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>became</td>\n",
       "      <td>(4.048305063534577, 0.044215717944225866)</td>\n",
       "      <td>4.048305</td>\n",
       "      <td>0.044216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>before</td>\n",
       "      <td>(4.048305063534577, 0.044215717944225866)</td>\n",
       "      <td>4.048305</td>\n",
       "      <td>0.044216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word                          chi-square-result  chi-square   p-value\n",
       "0   called  (4.048305063534577, 0.044215717944225866)    4.048305  0.044216\n",
       "1  country  (4.048305063534577, 0.044215717944225866)    4.048305  0.044216\n",
       "2   played  (4.048305063534577, 0.044215717944225866)    4.048305  0.044216\n",
       "3   became  (4.048305063534577, 0.044215717944225866)    4.048305  0.044216\n",
       "4   before  (4.048305063534577, 0.044215717944225866)    4.048305  0.044216"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_50_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe needs a bit cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chi_50_df[\"chi-square\"] = chi_50_df[\"chi-square-result\"].str[0]\n",
    "chi_50_df[\"p-value\"] = chi_50_df[\"chi-square-result\"].str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>chi-square</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>country</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>because</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>reports</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>founded</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>character</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>targetblankthisa</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>include</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>million</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>number</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>school</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>popular</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>father</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>through</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>between</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>classic</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>german</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>italian</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>george</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>former</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>leader</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>another</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>america</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>william</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>english</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>states</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>called</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>series</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>national</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>played</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>became</td>\n",
       "      <td>30.705096</td>\n",
       "      <td>3.003752e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>leader</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>another</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>america</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>william</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>english</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>reports</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>states</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>series</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>national</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>before</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>president</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>capital</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>american</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>famous</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>targetblankherea</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>french</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>island</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>people</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>largest</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>company</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>little</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>around</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>british</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>author</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>meaning</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>during</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>century</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>family</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>musical</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>between</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>9.791253e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word  chi-square       p-value\n",
       "501            country   30.705096  3.003752e-08\n",
       "538            because   30.705096  3.003752e-08\n",
       "528            reports   30.705096  3.003752e-08\n",
       "529            founded   30.705096  3.003752e-08\n",
       "530          character   30.705096  3.003752e-08\n",
       "531   targetblankthisa   30.705096  3.003752e-08\n",
       "532            include   30.705096  3.003752e-08\n",
       "533            million   30.705096  3.003752e-08\n",
       "534             number   30.705096  3.003752e-08\n",
       "535             school   30.705096  3.003752e-08\n",
       "536            popular   30.705096  3.003752e-08\n",
       "537             father   30.705096  3.003752e-08\n",
       "539            through   30.705096  3.003752e-08\n",
       "526            between   30.705096  3.003752e-08\n",
       "540            classic   30.705096  3.003752e-08\n",
       "541             german   30.705096  3.003752e-08\n",
       "542            italian   30.705096  3.003752e-08\n",
       "543             george   30.705096  3.003752e-08\n",
       "544             former   30.705096  3.003752e-08\n",
       "545             leader   30.705096  3.003752e-08\n",
       "546            another   30.705096  3.003752e-08\n",
       "547            america   30.705096  3.003752e-08\n",
       "548            william   30.705096  3.003752e-08\n",
       "549            english   30.705096  3.003752e-08\n",
       "527             states   30.705096  3.003752e-08\n",
       "500             called   30.705096  3.003752e-08\n",
       "525             series   30.705096  3.003752e-08\n",
       "513           national   30.705096  3.003752e-08\n",
       "502             played   30.705096  3.003752e-08\n",
       "503             became   30.705096  3.003752e-08\n",
       "...                ...         ...           ...\n",
       "1545            leader    0.000685  9.791253e-01\n",
       "1546           another    0.000685  9.791253e-01\n",
       "1547           america    0.000685  9.791253e-01\n",
       "1548           william    0.000685  9.791253e-01\n",
       "1549           english    0.000685  9.791253e-01\n",
       "1528           reports    0.000685  9.791253e-01\n",
       "1527            states    0.000685  9.791253e-01\n",
       "1525            series    0.000685  9.791253e-01\n",
       "1513          national    0.000685  9.791253e-01\n",
       "1504            before    0.000685  9.791253e-01\n",
       "1505         president    0.000685  9.791253e-01\n",
       "1506           capital    0.000685  9.791253e-01\n",
       "1507          american    0.000685  9.791253e-01\n",
       "1508            famous    0.000685  9.791253e-01\n",
       "1509  targetblankherea    0.000685  9.791253e-01\n",
       "1510            french    0.000685  9.791253e-01\n",
       "1511            island    0.000685  9.791253e-01\n",
       "1512            people    0.000685  9.791253e-01\n",
       "1514           largest    0.000685  9.791253e-01\n",
       "1524           company    0.000685  9.791253e-01\n",
       "1515            little    0.000685  9.791253e-01\n",
       "1516            around    0.000685  9.791253e-01\n",
       "1517           british    0.000685  9.791253e-01\n",
       "1518            author    0.000685  9.791253e-01\n",
       "1519           meaning    0.000685  9.791253e-01\n",
       "1520            during    0.000685  9.791253e-01\n",
       "1521           century    0.000685  9.791253e-01\n",
       "1522            family    0.000685  9.791253e-01\n",
       "1523           musical    0.000685  9.791253e-01\n",
       "1526           between    0.000685  9.791253e-01\n",
       "\n",
       "[2500 rows x 3 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_50_clean = chi_50_df.sort_values(\"chi-square\", ascending=False)\n",
    "chi_50_clean.drop(\"chi-square-result\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ordered the data frame by chi-square values in descending order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like these words are significantly different in usage between high value and low value questions. The p_values are lower than 0.05, and some of them are very close to 0 so the chi-squared test is valid. It would be helpful to study these words for the show."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
